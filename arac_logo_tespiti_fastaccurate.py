
# =============================================================================
# 		            ARAÃ‡ LOGOSU TESPÄ°T UYGULAMASI (BÄ°RLEÅTÄ°RÄ°LMÄ°Å VERSÄ°YON)
# =============================================================================
#
# BU KOD, TARAFINIZDAN SAÄLANAN Ä°KÄ° FARKLI VERSÄ°YONUN EN Ä°YÄ° YÃ–NLERÄ°NÄ° BÄ°RLEÅTÄ°RÄ°R:
#
# 1. FOTOÄRAF Ä°ÅLEME:
#    - Ä°lk kodunuzdaki `process_image` fonksiyonu BÄ°REBÄ°R KORUNMUÅTUR.
#    - Ã–zellikle kÃ¼Ã§Ã¼k logolarÄ± tespit etmek iÃ§in gÃ¶rÃ¼ntÃ¼yÃ¼ parÃ§alara ayÄ±rarak
#      analiz eden "YÃ¼ksek DoÄŸruluk Modu" aynen Ã§alÄ±ÅŸmaktadÄ±r.
#
# 2. VÄ°DEO Ä°ÅLEME:
#    - Ä°kinci kodunuzdaki hÄ±zlÄ± ve verimli `process_video` mantÄ±ÄŸÄ± alÄ±nmÄ±ÅŸtÄ±r.
#    - YOLOv8'in kendi optimize edilmiÅŸ takipÃ§ilerini ("ByteTrack", "BoT-SORT") kullanÄ±r.
#    - FFmpeg'i daha saÄŸlam bir ÅŸekilde Ã§aÄŸÄ±rarak uyumluluk sorunlarÄ±nÄ± azaltÄ±r.
#    - Kare atlama (frame-skip), hÄ±zlÄ± Ã¶nizleme gibi performans ayarlarÄ± eklenmiÅŸtir.
#
# 3. ARAYÃœZ ve YAPI:
#    - Ä°lk kodun `LogoDetector` sÄ±nÄ±f yapÄ±sÄ± ve genel Streamlit arayÃ¼z akÄ±ÅŸÄ±
#      (session_state yÃ¶netimi, UI fonksiyonlarÄ±) temel alÄ±nmÄ±ÅŸtÄ±r.
#    - Ä°kinci kodun video ayarlarÄ± (takipÃ§i seÃ§imi, kare atlama vb.) bu yapÄ±ya
#      entegre edilmiÅŸtir.
#
# =============================================================================

# GEREKSÄ°NÄ°MLER:
# pip install streamlit ultralytics opencv-python torch torchvision Pillow vidstab imageio-ffmpeg

import streamlit as st
import cv2
import numpy as np
import torch
import tempfile
import time
import subprocess
from pathlib import Path
from PIL import Image
from io import BytesIO
from ultralytics import YOLO
from torchvision.ops import nms
from typing import Generator, Any, Dict

# imageio_ffmpeg, ffmpeg binary dosyasÄ±nÄ±n yolunu gÃ¼venilir bir ÅŸekilde bulur.
# Bu, Ã¶zellikle farklÄ± sistemlerde (Ã¶rn. Streamlit Cloud) daÄŸÄ±tÄ±m yaparken hatalarÄ± Ã¶nler.
import imageio_ffmpeg

# ------------------ STIL ve Ã–N YÃœKLEME ---------------------------------
def inject_css():
    """Uygulama iÃ§in Ã¶zel CSS stillerini enjekte eder."""
    st.markdown("""
        <style>
        .frame{position:relative;width:100%;padding-top:56.25%;border:2px solid #666;border-radius:10px;background:#181818;overflow:hidden;display:flex;align-items:center;justify-content:center;}
        .frame img,.frame video{position:absolute;inset:0;width:100%!important;height:100%!important;object-fit:contain;}
        div[data-testid="stFileUploadList"]{display:none!important;}
        .overlay-modal{position:fixed;inset:0;background:rgba(24,24,24,.57);backdrop-filter:blur(2px);display:flex;align-items:center;justify-content:center;z-index:1000;}
        .modal-content{padding:2.1rem 3.3rem;border-radius:18px;background:#21232c;color:#fff;font-weight:600;font-size:1.22rem;box-shadow:0 6px 20px #000a;text-align:center;}
        .spin{width:42px;height:42px;border:4px solid #8ec6ff;border-left-color:transparent;border-radius:50%;animation:spin 1s linear infinite;margin:0 auto 1rem;}
        @keyframes spin{to{transform:rotate(360deg);}}
        </style>
    """, unsafe_allow_html=True)

@st.cache_resource(show_spinner="ğŸ§  Model belleÄŸe yÃ¼kleniyor...")
def load_yolo_model(path: str) -> YOLO:
    """YOLO modelini yÃ¼kler ve Ã¶nbelleÄŸe alÄ±r. Varsa GPU'ya taÅŸÄ±r."""
    model = YOLO(path)
    if torch.cuda.is_available():
        st.success("âœ… CUDA (GPU) desteÄŸi bulundu, model GPU'ya yÃ¼kleniyor.")
        model.to("cuda")
    else:
        st.warning("âš ï¸ CUDA (GPU) desteÄŸi bulunamadÄ±. Model CPU Ã¼zerinde Ã§alÄ±ÅŸacak.")
    return model

# ------------------ MANTIK KATMANI: LogoDetector SÄ±nÄ±fÄ± --------------------------
class LogoDetector:
    def __init__(self, model: YOLO):
        self.model = model

    # !!! Ã–NEMLÄ°: BU FONKSÄ°YON Ä°LK KODDAN HÄ°Ã‡ DEÄÄ°ÅTÄ°RÄ°LMEDEN ALINMIÅTIR !!!
    # YÃ¼ksek doÄŸruluk modu, kÃ¼Ã§Ã¼k nesneleri bulmak iÃ§in geliÅŸmiÅŸ bir mantÄ±k kullanÄ±r.
    def process_image(self, image_np: np.ndarray, conf: float, imgsz: int, high_accuracy: bool) -> np.ndarray:
        """Bir gÃ¶rÃ¼ntÃ¼yÃ¼ iÅŸler ve logolarÄ± tespit eder."""
        if not high_accuracy:
            # Standart, hÄ±zlÄ± tespit
            return self.model.predict(image_np, conf=conf, imgsz=imgsz, verbose=False)[0].plot(img=image_np.copy())
        
        # YÃ¼ksek DoÄŸruluk Modu: GÃ¶rÃ¼ntÃ¼yÃ¼ 4 parÃ§aya bÃ¶l ve ayrÄ±ca tamamÄ±nÄ± analiz et.
        h, w = image_np.shape[:2]
        with torch.inference_mode():
            # 1. TÃ¼m gÃ¶rÃ¼ntÃ¼ Ã¼zerinde tespit yap
            full_results = self.model.predict(image_np, conf=conf, imgsz=imgsz, iou=0.45, max_det=300, verbose=False)[0]
            
            # 2. GÃ¶rÃ¼ntÃ¼yÃ¼ 4 Ã§eyreÄŸe bÃ¶l
            tiles = [image_np[y:y + h // 2, x:x + w // 2] for y in (0, h // 2) for x in (0, w // 2)]
            grid = [(x, y) for y in (0, h // 2) for x in (0, w // 2)]
            
            # 3. Her bir parÃ§a Ã¼zerinde tespit yap
            tile_parts = self.model.predict(tiles, conf=conf, imgsz=imgsz, iou=0.45, max_det=300, verbose=False)

        all_boxes_list = []
        if hasattr(full_results.boxes, "data") and len(full_results.boxes.data) > 0:
            all_boxes_list.append(full_results.boxes.data)
        
        # 4. ParÃ§alardan gelen kutu koordinatlarÄ±nÄ± orijinal gÃ¶rÃ¼ntÃ¼ye gÃ¶re ayarla
        for res, (gx, gy) in zip(tile_parts, grid):
            if hasattr(res.boxes, "data") and len(res.boxes.data) > 0:
                offset = torch.tensor([gx, gy, gx, gy], dtype=res.boxes.data.dtype, device=res.boxes.data.device)
                cloned_boxes = res.boxes.data.clone()
                cloned_boxes[:, :4] += offset
                all_boxes_list.append(cloned_boxes)
        
        if not all_boxes_list:
            return full_results.plot(img=image_np.copy())
            
        # 5. TÃ¼m kutularÄ± birleÅŸtir ve Non-Maximum Suppression (NMS) ile Ã§akÄ±ÅŸanlarÄ± temizle
        combined_boxes = torch.cat(all_boxes_list, 0)
        final_results = full_results
        unique_classes = combined_boxes[:, 5].unique()
        
        class_specific_boxes = []
        for c in unique_classes:
            class_mask = combined_boxes[:, 5] == c
            class_boxes_data = combined_boxes[class_mask]
            keep = nms(class_boxes_data[:, :4], class_boxes_data[:, 4], iou_threshold=0.40)
            class_specific_boxes.append(class_boxes_data[keep])

        if not class_specific_boxes:
            final_results.boxes.data = torch.empty((0, 6), device=combined_boxes.device)
            return final_results.plot(img=image_np.copy())
            
        cleaned_boxes_stage1 = torch.cat(class_specific_boxes, 0)
        
        # 6. Ä°kinci aÅŸama NMS (farklÄ± sÄ±nÄ±flar arasÄ±nda Ã§akÄ±ÅŸma olabilir)
        keep_stage2 = nms(cleaned_boxes_stage1[:, :4], cleaned_boxes_stage1[:, 4], iou_threshold=0.40)
        cleaned_boxes_stage2 = cleaned_boxes_stage1[keep_stage2]

        # 7. Ä°Ã§ iÃ§e geÃ§miÅŸ kutularÄ± temizle (bÃ¼yÃ¼k olanÄ±n iÃ§inde kÃ¼Ã§Ã¼k ve aynÄ± tespit varsa)
        sorted_indices = torch.argsort(cleaned_boxes_stage2[:, 4], descending=True)
        sorted_boxes = cleaned_boxes_stage2[sorted_indices]
        
        to_keep_mask = torch.ones(sorted_boxes.shape[0], dtype=torch.bool, device=sorted_boxes.device)
        for i in range(sorted_boxes.shape[0]):
            if not to_keep_mask[i]: continue
            for j in range(i + 1, sorted_boxes.shape[0]):
                if not to_keep_mask[j]: continue
                
                inter_x1, inter_y1 = torch.max(sorted_boxes[i, 0], sorted_boxes[j, 0]), torch.max(sorted_boxes[i, 1], sorted_boxes[j, 1])
                inter_x2, inter_y2 = torch.min(sorted_boxes[i, 2], sorted_boxes[j, 2]), torch.min(sorted_boxes[i, 3], sorted_boxes[j, 3])
                intersection = torch.clamp(inter_x2 - inter_x1, min=0) * torch.clamp(inter_y2 - inter_y1, min=0)
                area_j = (sorted_boxes[j, 2] - sorted_boxes[j, 0]) * (sorted_boxes[j, 3] - sorted_boxes[j, 1])
                
                if area_j > 0 and intersection / area_j > 0.9: # EÄŸer kutu j, kutu i'nin %90'Ä±ndan fazlasÄ±nÄ± kaplÄ±yorsa
                    to_keep_mask[j] = False

        final_results.boxes.data = sorted_boxes[to_keep_mask]
        return final_results.plot(img=image_np.copy())

    # --- YENÄ° VÄ°DEO Ä°ÅLEME FONKSÄ°YONU ---
    # Bu fonksiyon, ikinci kodun hÄ±zlÄ± ve verimli mantÄ±ÄŸÄ±nÄ± kullanÄ±r.
    def process_video(self, video_path: str, conf: float, imgsz: int, skip_n: int, tracker: str, stabilize: bool, fast_preview: bool) -> Generator[Any, None, None]:
        """Bir videoyu iÅŸler, logolarÄ± tespit eder ve takip eder."""
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            st.error("ğŸ¥ Video dosyasÄ± aÃ§Ä±lamadÄ±."); return

        fps = cap.get(cv2.CAP_PROP_FPS) or 30
        W, H = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 1

        # 1. AdÄ±m: Ham iÅŸlenmiÅŸ videoyu geÃ§ici bir .avi dosyasÄ±na yaz.
        # MJPG codec, Ã§oÄŸu sistemde ek sÃ¼rÃ¼cÃ¼ gerektirmeden Ã§alÄ±ÅŸtÄ±ÄŸÄ± iÃ§in gÃ¼venilirdir.
        avi_tmp_path = tempfile.mktemp(suffix=".avi")
        writer = cv2.VideoWriter(avi_tmp_path, cv2.VideoWriter_fourcc(*"MJPG"), fps, (W, H))
        if not writer.isOpened():
            st.error("âŒ GeÃ§ici video yazÄ±cÄ± (MJPG codec) oluÅŸturulamadÄ±."); return

        # Opsiyonel video sabitleme (stabilizasyon)
        stabilizer = None
        if stabilize:
            try:
                from vidstab import VidStab
                stabilizer = VidStab()
            except ImportError:
                st.warning("â–¶ï¸ `vidstab` kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil, stabilizasyon atlanÄ±yor.")

        # TakipÃ§i yapÄ±landÄ±rmasÄ±nÄ± seÃ§
        tracker_config = "bytetrack.yaml" if tracker == "ByteTrack" else "botsort.yaml"
        
        last_tracked_result = None
        start_time = time.time()

        for frame_idx in range(total_frames):
            ret, frame = cap.read()
            if not ret: break

            yield (frame_idx / total_frames, f"ğŸ¬ Kare {frame_idx}/{total_frames} iÅŸleniyor...")

            annotated_frame = frame
            # Her (skip_n + 1) karede bir tespit yap, aradaki karelerde son sonucu kullan
            if frame_idx % (skip_n + 1) == 0:
                last_tracked_result = self.model.track(
                    frame,
                    conf=conf,
                    imgsz=imgsz,
                    tracker=tracker_config,
                    persist=True,  # Kareler arasÄ±nda takibi sÃ¼rdÃ¼r
                    verbose=False
                )[0]
            
            # EÄŸer bir tespit sonucu varsa, Ã§iz; yoksa orijinal kareyi kullan
            if last_tracked_result:
                annotated_frame = last_tracked_result.plot()

            if stabilizer:
                stabilized_output = stabilizer.stabilize_frame(input_frame=annotated_frame, border_size=10)
                if stabilized_output is not None:
                    annotated_frame = stabilized_output
            
            writer.write(cv2.resize(annotated_frame, (W, H)))

        cap.release()
        writer.release()
        
        yield (1.0, f"âœ… {total_frames} kare {time.time() - start_time:.1f} saniyede iÅŸlendi. Video yeniden kodlanÄ±yor...")

        # 2. AdÄ±m: OluÅŸturulan .avi dosyasÄ±nÄ± tarayÄ±cÄ± uyumlu H.264 MP4 formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r.
        # Bu yÃ¶ntem, 'ffmpeg-python' kÃ¼tÃ¼phanesinden daha kararlÄ± Ã§alÄ±ÅŸÄ±r.
        final_out_path = tempfile.mktemp(suffix=".mp4")
        scale_filter = "scale=iw*0.5:-2" if fast_preview else "scale=iw:-2"
        ffmpeg_executable = imageio_ffmpeg.get_ffmpeg_exe()
        
        cmd = [
            ffmpeg_executable, "-y", "-loglevel", "error", "-i", avi_tmp_path,
            "-vf", scale_filter,
            "-vcodec", "libx264", "-preset", "ultrafast",
            "-b:v", "1.5M", # Kalite iÃ§in bitrate biraz artÄ±rÄ±ldÄ±
            "-pix_fmt", "yuv420p", "-movflags", "+faststart",
            "-an", # Sesi kaldÄ±r
            final_out_path
        ]
        
        try:
            subprocess.run(cmd, check=True)
            with open(final_out_path, "rb") as f:
                yield f.read() # Final video baytlarÄ±nÄ± gÃ¶nder
        except subprocess.CalledProcessError as e:
            st.error(f"FFmpeg yeniden kodlama hatasÄ±! Komut Ã§alÄ±ÅŸtÄ±rÄ±lamadÄ±. Hata: {e}")
            yield None
        except Exception as e:
            st.error(f"Video dosyasÄ± okunurken hata oluÅŸtu: {e}")
            yield None


# ------------------ SUNUM KATMANI --------------------------
def setup_sidebar(processing_mode: str) -> Dict[str, Any]:
    """Kenar Ã§ubuÄŸundaki ayar kontrollerini oluÅŸturur ve ayarlarÄ± dÃ¶ndÃ¼rÃ¼r."""
    st.sidebar.title("âš™ï¸ Ayarlar")
    settings = {
        "conf": st.sidebar.slider("GÃ¼ven EÅŸiÄŸi", 0.05, 1.0, 0.30, 0.05),
        "imgsz": st.sidebar.select_slider("GÃ¶rÃ¼ntÃ¼ Boyutu (px)", options=[320, 480, 640, 720, 1080, 1280], value=640)
    }
    st.sidebar.markdown("---")

    if processing_mode == "FotoÄŸraf":
        settings["high_accuracy"] = st.sidebar.checkbox("YÃ¼ksek DoÄŸruluk Modu", value=True, help="KÃ¼Ã§Ã¼k logolarÄ± daha iyi bulmak iÃ§in gÃ¶rÃ¼ntÃ¼yÃ¼ parÃ§alara ayÄ±rarak tarar. Daha yavaÅŸ Ã§alÄ±ÅŸÄ±r.")
    else:
        st.sidebar.header("Video Parametreleri")
        settings["skip_n"] = st.sidebar.slider("Kare Atlama (Frame-Skip)", 0, 10, 1, help="PerformansÄ± artÄ±rmak iÃ§in her N karede bir tespit yapar.")
        settings["tracker"] = st.sidebar.selectbox("TakipÃ§i AlgoritmasÄ±", ["ByteTrack", "BoT-SORT"])
        settings["stabilize"] = st.sidebar.checkbox("Videoyu Sabitle (Deneysel)", value=False, help="VidStab kÃ¼tÃ¼phanesi ile videodaki titreÅŸimi azaltmaya Ã§alÄ±ÅŸÄ±r.")
        settings["fast_preview"] = st.sidebar.checkbox("âš¡ HÄ±zlÄ± Ã–nizleme", value=False, help="SonuÃ§ videosunu daha dÃ¼ÅŸÃ¼k Ã§Ã¶zÃ¼nÃ¼rlÃ¼kte ve boyutta oluÅŸturur.")
        
    return settings

def main_ui(detector: LogoDetector):
    """Ana kullanÄ±cÄ± arayÃ¼zÃ¼nÃ¼ oluÅŸturur ve yÃ¶netir."""
    st.markdown("##  AraÃ§ Logosu Tespiti ")
    
    processing_mode = st.radio("Ä°ÅŸlem Tipi:", ("FotoÄŸraf", "Video"), horizontal=True, key="processing_mode_radio")

    # Mod deÄŸiÅŸtiÄŸinde eski sonuÃ§larÄ± temizle
    if 'current_mode' not in st.session_state or st.session_state.current_mode != processing_mode:
        st.session_state.current_mode = processing_mode
        if 'processed_media' in st.session_state:
            del st.session_state.processed_media
        if 'uploaded_file_name' in st.session_state:
            del st.session_state.uploaded_file_name
    
    settings = setup_sidebar(processing_mode)

    uploader_label = "Bir FotoÄŸraf YÃ¼kleyin" if processing_mode == "FotoÄŸraf" else "Bir Video YÃ¼kleyin"
    uploader_types = ["png", "jpg", "jpeg", "webp", "bmp"] if processing_mode == "FotoÄŸraf" else ["mp4", "mov", "avi", "mkv"]
    
    uploaded_file = st.file_uploader(uploader_label, type=uploader_types, key="file_uploader")

    # Yeni dosya yÃ¼klendiÄŸinde eski sonuÃ§larÄ± temizle
    if uploaded_file is not None:
        if 'uploaded_file_name' not in st.session_state or st.session_state.uploaded_file_name != uploaded_file.name:
            st.session_state.uploaded_file_name = uploaded_file.name
            if 'processed_media' in st.session_state:
                del st.session_state.processed_media

    col_left, col_right = st.columns(2, gap="large")
    with col_left:
        st.markdown("#### Orijinal Dosya")
        if uploaded_file:
            if processing_mode == "FotoÄŸraf":
                st.image(uploaded_file, use_container_width=True)
            else:
                st.video(uploaded_file)
        else:
            st.markdown('<div class="frame"></div>', unsafe_allow_html=True)
    
    with col_right:
        st.markdown("#### Tespit Sonucu")
        if 'processed_media' in st.session_state:
            if processing_mode == "FotoÄŸraf":
                st.image(st.session_state.processed_media, use_container_width=True)
            else:
                st.video(st.session_state.processed_media)
        else:
            st.markdown('<div class="frame"></div>', unsafe_allow_html=True)

    if uploaded_file and 'processed_media' not in st.session_state:
        modal = st.empty()
        modal.markdown('<div class="overlay-modal"><div class="modal-content"><div class="spin"></div>Model ile iÅŸleniyorâ€¦</div></div>', unsafe_allow_html=True)
        
        if processing_mode == "FotoÄŸraf":
            image_np = np.array(Image.open(uploaded_file).convert("RGB"))
            annotated_image = detector.process_image(image_np, **settings)
            st.session_state.processed_media = annotated_image
            st.toast("âœ… FotoÄŸraf iÅŸlendi!", icon="ğŸ–¼ï¸")
        else:
            with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp:
                tmp.write(uploaded_file.getvalue())
                video_path = tmp.name
            
            progress_bar = st.progress(0.0, "HazÄ±rlanÄ±yor...")
            video_generator = detector.process_video(video_path=video_path, **settings)
            
            for result in video_generator:
                if isinstance(result, tuple):
                    progress, status_text = result
                    progress_bar.progress(progress, text=status_text)
                elif result is not None:
                    st.session_state.processed_media = result
            
            progress_bar.empty()
            if 'processed_media' in st.session_state:
                 st.toast("âœ… Video takip ile tamamlandÄ±!", icon="ğŸ‰")
            else:
                 st.error("âŒ Video iÅŸlenirken bir hata oluÅŸtu ve sonuÃ§ Ã¼retilemedi.")


        modal.empty()
        st.rerun()

    if processing_mode == "Video" and 'processed_media' in st.session_state:
        st.download_button("ğŸ“¥ SonuÃ§ Videosunu Ä°ndir", st.session_state.processed_media, "sonuc.mp4", "video/mp4")

if __name__ == "__main__":
    st.set_page_config(page_title="AraÃ§ Logosu Tespiti", layout="wide", initial_sidebar_state="expanded")
    inject_css()
    model = load_yolo_model("best.pt")
    detector = LogoDetector(model)
    main_ui(detector)
